<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Point Cloud Segmentation for 3D Clothed Human Layering</title>
  <meta name="description" content="Point Cloud Segmentation for 3D Clothed Human Layering" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.4/css/academicons.min.css">  <style>
    :root {
      --bg: #ffffff;
      --panel: #f7f7f9;
      --text: #1a1a1a;
      --muted: #555;
      --accent: #2563eb;
      --accent-2: #059669;
      --border: #e0e0e0;
      --link: #2563eb;
      --maxw: 1024px;
    }
    html, body { margin: 0; padding: 0; background: var(--bg); color: var(--text); font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji"; }
    a { color: var(--link); text-decoration: none; }
    a:hover { text-decoration: underline; }
    .wrap { max-width: var(--maxw); margin: 0 auto; padding: 24px; }
    header { text-align: center; padding: 48px 0 24px; }
    h1 { font-size: clamp(32px, 5vw, 48px); margin: 0 0 8px; letter-spacing: 0.2px; }
    .subtitle { font-size: clamp(18px, 2.4vw, 24px); color: var(--muted); margin: 0 0 12px; }
    .conf { font-weight: 600; color: var(--accent); margin: 8px 0 16px; }
    .authors { margin: 12px auto 4px; display: flex; flex-wrap: wrap; gap: 8px 14px; justify-content: center; color: var(--text); }
    .authors a { color: var(--text); border-bottom: 1px dotted var(--border); text-decoration: none; }
    .affils { text-align: center; color: var(--muted); margin-top: 6px; }
    .badges { display: flex; flex-wrap: wrap; gap: 10px; justify-content: center; margin: 20px 0 28px; }
    .badge { background: linear-gradient(180deg, #ffffff, #f1f5f9); border: 1px solid var(--border); color: var(--text); padding: 10px 14px; border-radius: 12px; display: inline-flex; align-items: center; gap: 8px; font-weight: 600; }
    .badge:hover { border-color: #cbd5e1; transform: translateY(-1px); transition: all .15s ease; text-decoration: none; }
    .teaser { background: var(--panel); border: 1px solid var(--border); border-radius: 16px; overflow: hidden; }
    .teaser img, .figure img { width: 100%; height: auto; display: block; }
    .section { padding: 36px 0; }
    .section h2 { font-size: clamp(22px, 3vw, 28px); margin: 0 0 14px; }
    .lead { color: var(--muted); line-height: 1.6; font-size: 18px; }
    .grid { display: grid; grid-template-columns: repeat(12, 1fr); gap: 16px; }
    .col-12 { grid-column: span 12; }
    .col-6 { grid-column: span 12; }
    @media (min-width: 800px) { .col-6 { grid-column: span 6; } }
    .panel { background: var(--panel); border: 1px solid var(--border); border-radius: 14px; padding: 16px; }
    .figure { background: var(--panel); border: 1px solid var(--border); border-radius: 16px; overflow: hidden; }
    .numlist { counter-reset: step; list-style: none; padding: 0; }
    .numlist li { counter-increment: step; margin: 10px 0; padding-left: 36px; position: relative; line-height: 1.6; }
    .numlist li::before { content: counter(step) "."; position: absolute; left: 0; top: 0; font-weight: 800; color: var(--accent-2); }
    pre { background: #f3f4f6; color: #111; border: 1px solid var(--border); border-radius: 12px; padding: 14px; overflow-x: auto; }
    code { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; font-size: 0.95em; }
    .footer { color: var(--muted); border-top: 1px dashed var(--border); padding-top: 24px; margin-top: 24px; text-align: center; }
    nav { position: sticky; top: 0; background: rgba(255,255,255,0.9); backdrop-filter: blur(8px); border-bottom: 1px solid var(--border); z-index: 10; }
    nav .navwrap { max-width: var(--maxw); margin: 0 auto; display: flex; gap: 16px; align-items: center; padding: 10px 16px; }
    nav a { color: var(--muted); font-weight: 600; }
    nav a:hover { color: var(--text); }
    .spacer { height: 6px; }
  </style>
</head>
<body>
  <div id="top" class="wrap">
    <header>
      <h1>Point Cloud Segmentation for 3D Clothed Human Layering</h1>
      <p class="subtitle">A multilayer segmentation paradigm for clothed-human point clouds</p>
      <p class="conf">Computers & Graphics</p>
      <div class="authors">
        <span><a href="https://scholar.google.com/citations?user=C6KZLEsAAAAJ&hl=it">Davide Garavaso</a><sup>1</sup></span>
        <span><a href="https://scholar.google.com/citations?user=nL8n2dwAAAAJ&hl=en">Federico Masi</a><sup>2</sup></span>
        <span><a href="https://scholar.google.com/citations?user=21Jw3joAAAAJ&hl=it">Pietro Musoni</a><sup>3</sup></span>
        <span><a href="https://scholar.google.com/citations?user=yxZNqcsAAAAJ&hl=it">Umberto Castellani</a><sup>4</sup></span>
      </div>
      <div class="affils"> University of Verona</div>
      <div class="badges">
        <a class="badge" id="code" href="https://github.com/PietroMsn/Multilayer-Segmentation" target="_blank" rel="noopener"><img src='https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/github.svg' alt='github' height='20'> Code</a>
        <a class="badge" id="code" href="https://github.com/PietroMsn/Scanned-Gim3D" target="_blank" rel="noopener"><img src='https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/github.svg' alt='github' height='20'> Dataset</a>
        <a class="badge" href="https://www.sciencedirect.com/science/article/pii/S0097849325002341" target="_blank" rel="noopener">üìÑ Computers & Graphics</a>
        <a class="badge" href="#method">üß† Method</a>
        <a class="badge" href="#results">üñºÔ∏è Results</a>
      </div>
      <div class="teaser">
        <img src="assets/pipeline_dataset.jpg" alt="Project teaser image showing multilayer clothing segmentation" />
      </div>
    </header>

    <section class="section">
      <p class="lead">
        <strong>Clothed Human Layering.</strong> 
        3D Cloth modeling and simulation is essential for avatars creation in several fields, such as fashion, entertainment, and animation. Achieving high-quality results is challenging due to the large variability of clothed body especially in the generation of realistic wrinkles. 3D scan acquisitions provide more accuracy in the representation of real-world objects but lack semantic information that can be inferred with a reliable semantic reconstruction pipeline. To this aim, shape segmentation plays a crucial role in identifying the semantic shape parts. However, current 3D shape segmentation methods are designed for scene understanding and interpretation and only few work is devoted to modeling. In the context of clothed body modeling the segmentation is a preliminary step for fully semantic shape parts reconstruction namely the underlying body and the involved garments. These parts represent several layers with strong overlap in contrast with standard segmentation methods that provide disjoint sets. In this work we propose a new 3D point cloud segmentation paradigm where each 3D point can be simultaneously associated to different layers. In this fashion we can estimate the underlying body parts and the unseen clothed regions, i.e., the part of a cloth occluded by the clothed-layer above. We name this segmentation paradigm clothed human layering. We create a new synthetic dataset that simulates very realistic 3D scans with the ground truth of the involved clothing layers. We propose and evaluate different neural network settings to deal with 3D clothing layering. We considered both coarse and fine grained per-layer garment identification. Our experiments demonstrates the benefit in introducing proper strategies for the segmentation on the garment domain on both the synthetic and real-world scan datasets.
      </p>
    </section>

    <section id="dataset" class="section">
      <h2>Gim3d scanned</h2>
      <p class="lead">
        The Gim3D Scanned Dataset provides high-quality 3D scans of clothed humans with detailed geometry and realistic clothing layers.
It is derived from synthetic data scanned with a virtual scanner that reproduces noise and artifacts similar to real-world acquisitions.
This dataset enables research on multilayer point cloud segmentation, including both visible and occluded garment regions, and serves as a benchmark for 3D reconstruction, virtual try-on, and human digitization.
      </p>
        <img src="assets/gim3d_scanned.jpg" alt="Gim3d scanned" style="width:60%;max-width:500px;display:block;margin:0 auto;">
    </section>

    <section id="method" class="section">
      <h2>Method</h2>
      <div class="grid">
        <div class="col-12 figure"><img src="assets/pipeline.jpg" alt="Pipeline diagram"></div>
        <div class="col-12 panel">
          <ol class="numlist">
            <li><strong>Multilayer labeling.</strong> Predict layer memberships per point (body, garment types) including occluded regions.</li>
            <li><strong>Feature heads.</strong> Use invariant features for class probabilities and confidences; use (optionally) equivariant features for geometric cues.</li>
            <li><strong>Training data.</strong> Synthetic scans with multi-layer ground truth; evaluate on both synthetic and real scans.</li>
          </ol>
        </div>
      </div>
    </section>

    <section id="results" class="section">
      <h2>Results</h2>
      <div class="grid">
        <div class="col-6 figure"><img src="assets/result_01.jpg" alt="Result 1"></div>
        <div class="col-6 figure"><img src="assets/result_02.jpg" alt="Result 2"></div>
        <div class="col-6 figure"><img src="assets/result_03.jpg" alt="Result 3"></div>
        <div class="col-6 figure"><img src="assets/result_04.jpg" alt="Result 4"></div>
      </div>
      <p style="margin-top:10px;color:var(--muted)">Add more results or link to a gallery page.</p>
    </section>

    <section id="bibtex" class="section">
      <h2>BibTeX</h2>
      <pre><code>
        @article{garavaso2025point,
        title={Point cloud segmentation for 3D Clothed Human Layering},
        author={Garavaso, Davide and Masi, Federico and Musoni, Pietro and Castellani, Umberto},
        journal={Computers \& Graphics},
        pages={104393},
        year={2025},
        publisher={Elsevier}}
</code></pre>
    </section>

    <section class="section">
      <h2>Resources</h2>
      <div class="grid">
        <div class="col-6 panel">
          <h3 style="margin-top:0">Code & Data</h3>
          <ul>
            <li><a href="https://github.com/PietroMsn/Multilayer-Segmentation">GitHub Repository</a></li>
            <li><a href="https://github.com/PietroMsn/GIM3D">Gim3d dataset</a></li>
            <li><a href="https://github.com/PietroMsn/Scanned-Gim3D">Gim3d scanned dataset</a></li>
          </ul>
        </div>
        <div class="col-6 panel">
          <h3 style="margin-top:0">Contacts</h3>
          <ul>
            <li>davide.garavaso@gmail.com</li>
            <li>federico.masi@univr.it</li>
            <li>pietro.musoni@unipr.it</li>
            <li>umberto.castellani@univr.it</li>
          </ul>
        </div>
      </div>
    </section>

    <div class="footer">
      <p>¬© 2025 Authors. This page is built with GitHub Pages. Feel free to reuse this template; add attribution if useful.</p>
    </div>
  </div>

  <script>
    document.querySelectorAll('a[href^="#"]').forEach(a => {
      a.addEventListener('click', e => {
        const id = a.getAttribute('href').slice(1);
        const el = document.getElementById(id);
        if (el) {
          e.preventDefault();
          el.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });
  </script>
</body>
</html>
